{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Add bias in general\n",
    "- Add support for DataFrames\n",
    "- Normalize inputs\n",
    "- Minibatch\n",
    "- Dynamic learning rate (Hessian?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, deriv = False):\n",
    "    if deriv:\n",
    "        return x * (1-x)\n",
    "    else:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "np.random.seed(1)\n",
    "first_weights = 2 * np.random.random((3, 4)) - 1\n",
    "second_weights = 2 * np.random.random((4, 1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.496410031903\n",
      "Error:0.00772627511817\n",
      "Error:0.00523235948491\n",
      "Error:0.00419079975301\n",
      "Error:0.003587364709\n",
      "Error:0.00318289024928\n",
      "Error:0.00288809893045\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "high = 60000\n",
    "import numpy as np\n",
    "learning_rate = 1\n",
    "first_past_update = second_past_update = 0\n",
    "momentum = .2\n",
    "for j in range(high + 1):\n",
    "    first_neurons = sigmoid(np.dot(X,first_weights))\n",
    "    second_neurons = sigmoid(np.dot(first_neurons,second_weights))\n",
    "    second_error = y - second_neurons\n",
    "    if (j% 10000) == 0:\n",
    "        print(\"Error:\" + str(np.mean(np.abs(second_error))))\n",
    "    second_delta = (second_error) * (sigmoid(second_neurons, deriv = True))\n",
    "    first_error = (second_delta).dot(second_weights.T)\n",
    "    first_delta = first_error * (sigmoid(first_neurons, deriv = True))\n",
    "    first_update = learning_rate * X.T.dot(first_delta) + momentum * first_past_update\n",
    "    second_update = learning_rate * first_neurons.T.dot(second_delta) + momentum * second_past_update\n",
    "    first_weights += first_update \n",
    "    second_weights += second_update\n",
    "    first_past_update, second_past_update = first_update.copy(), second_update.copy()\n",
    "    \n",
    "    #second_weights += learning_rate * first_neurons.T.dot(second_delta)\n",
    "    #first_weights += learning_rate * X.T.dot(first_delta)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_bias(inputs):\n",
    "    \"\"\"Returns the list of inputs with a bias column.\"\"\"\n",
    "    return np.append(inputs, np.ones((inputs.shape[0], 1)), axis = 1)\n",
    "\n",
    "def biased(inputs):\n",
    "    \"\"\"A necessary but not sufficient condition for the inputs to be biased.\"\"\"\n",
    "    return (inputs[:,-1] == np.ones((inputs.shape[0], 1))).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "# Helper functions\n",
    "#\n",
    "\n",
    "def add_bias(inputs):\n",
    "    \"\"\"Returns the list of inputs with a bias column.\"\"\"\n",
    "    return np.append(inputs, np.ones((inputs.shape[0], 1)), axis = 1)\n",
    "\n",
    "def biased(inputs):\n",
    "    \"\"\"A necessary but not sufficient condition for the inputs to be biased.\"\"\"\n",
    "    return (inputs[:,-1] == np.ones((inputs.shape[0], 1))).all()\n",
    "\n",
    "#\n",
    "# The main class\n",
    "# \n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"A neural network with one hidden layer using the backpropagation algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, shape, momentum = 0, learning_rate = 1):\n",
    "        \"\"\"Initializes the network.\n",
    "        \n",
    "        The SHAPE parameter should be a tuple with the number of input columns\n",
    "        (including the bias column!!) as the first element, 1 as the last element,\n",
    "        and the number of hidden neurons in each layer as the middle elements.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.momentum = momentum\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize the weights to random values\n",
    "        self.first_weights = 2 * np.random.random((self.shape[0], self.shape[1])) - 1\n",
    "        self.second_weights = 2 * np.random.random((self.shape[1], self.shape[2])) - 1\n",
    "        \n",
    "    def sigmoid(self, x, deriv = False):\n",
    "        \"\"\"Returns the sigmoid function or its derivative of the input list.\"\"\"\n",
    "        if deriv:\n",
    "            return x * (1-x)\n",
    "        else:\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "                                \n",
    "    def run(self, inputs):\n",
    "        \"\"\"Runs the neural network on a set of inputs.\"\"\"\n",
    "        assert biased(inputs), \"Inputs need a bias column\"\n",
    "        self.first_layer_output = self.sigmoid(np.dot(inputs, self.first_weights))\n",
    "        self.second_layer_output = self.sigmoid(np.dot(self.first_layer_output, self.second_weights))\n",
    "        \n",
    "    def print_error(self):\n",
    "        print(\"Error:\" + str(np.mean(np.abs(self.error))))\n",
    "        \n",
    "    def train(self, inputs, target, num_loops = 5000, num_error_prints = 10):\n",
    "        \"\"\"Train the network on the INPUTS dataset (should be a numpy array).\"\"\"\n",
    "        \n",
    "        assert biased(inputs), \"Inputs need a bias column\"\n",
    "        first_past_update = second_past_update = 0\n",
    "        error_mod = num_loops // num_error_prints\n",
    "        for j in range(num_loops):\n",
    "            self.run(inputs)\n",
    "            self.error = target - self.second_layer_output\n",
    "            \n",
    "            # Print the error every ERROR_MOD iterations\n",
    "            if (j % error_mod) == 0:\n",
    "                self.print_error()\n",
    "            \n",
    "            # Determine the update amounts\n",
    "            second_delta = (self.error) * (self.sigmoid(self.second_layer_output, deriv = True))\n",
    "            first_layer_error = (second_delta).dot(self.second_weights.T)\n",
    "            first_delta = first_layer_error * (self.sigmoid(self.first_layer_output, deriv = True))\n",
    "            first_update = self.learning_rate * inputs.T.dot(first_delta) + self.momentum * first_past_update\n",
    "            second_update = self.learning_rate * self.first_layer_output.T.dot(second_delta) + self.momentum * second_past_update\n",
    "            \n",
    "            # Update the weights\n",
    "            self.first_weights += first_update\n",
    "            self.second_weights += second_update\n",
    "            first_past_update, second_past_update = first_update.copy(), second_update.copy()\n",
    "            \n",
    "def test():\n",
    "    X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "    y = np.array([[0,1,1,0]]).T\n",
    "    X = add_bias(X)\n",
    "    nn = NeuralNetwork((4,4,1))\n",
    "    nn.train(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.498444311931\n",
      "Error:0.0844139617943\n",
      "Error:0.0429739399936\n",
      "Error:0.0316160774682\n",
      "Error:0.0259303491811\n",
      "Error:0.0224057638067\n",
      "Error:0.0199616713199\n",
      "Error:0.0181450317216\n",
      "Error:0.0167293968623\n",
      "Error:0.0155877596775\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
